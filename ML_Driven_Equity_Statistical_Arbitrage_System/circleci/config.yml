version: 2.1

# Define orbs for common tasks
orbs:
  python: circleci/python@2.1.1
  docker: circleci/docker@2.2.0
  node: circleci/node@5.1.0

# Define executors for different environments
executors:
  python-executor:
    docker:
      - image: cimg/python:3.11
    working_directory: ~/project
    
  cpp-executor:
    docker:
      - image: cimg/base:2023.03
    working_directory: ~/project
    
  r-executor:
    docker:
      - image: rocker/r-ver:4.3.0
    working_directory: ~/project
    
  matlab-executor:
    docker:
      - image: mathworks/matlab:r2023a
    working_directory: ~/project
    
  kdb-executor:
    docker:
      - image: kxsys/kdb:4.0
    working_directory: ~/project

# Define commands for reusable steps
commands:
  checkout_and_cache:
    description: "Checkout code and restore caches"
    steps:
      - checkout
      - run:
          name: Create cache key files
          command: |
            echo "$(date +%Y-%m)" > /tmp/month-cache-key
            
  save_test_results:
    description: "Save test results and artifacts"
    parameters:
      test_results_path:
        type: string
        default: "test-results"
      artifacts_path:
        type: string
        default: "artifacts"
    steps:
      - store_test_results:
          path: << parameters.test_results_path >>
      - store_artifacts:
          path: << parameters.artifacts_path >>

# Define jobs for each component
jobs:
  # Python testing and linting job
  python-test:
    executor: python-executor
    resource_class: medium
    steps:
      - checkout_and_cache
      
      # Restore Python dependencies cache
      - restore_cache:
          keys:
            - python-deps-v2-{{ checksum "requirements.txt" }}-{{ checksum "/tmp/month-cache-key" }}
            - python-deps-v2-{{ checksum "requirements.txt" }}
            - python-deps-v2-
      
      # Set up Python environment
      - run:
          name: Create virtual environment
          command: |
            python -m venv venv
            source venv/bin/activate
            pip install --upgrade pip setuptools wheel
      
      # Install dependencies
      - run:
          name: Install Python dependencies
          command: |
            source venv/bin/activate
            pip install -r requirements.txt
            pip install flake8 mypy black pytest-cov pytest-html
      
      # Save Python dependencies cache
      - save_cache:
          key: python-deps-v2-{{ checksum "requirements.txt" }}-{{ checksum "/tmp/month-cache-key" }}
          paths:
            - venv
      
      # Run code formatting check
      - run:
          name: Check code formatting with Black
          command: |
            source venv/bin/activate
            black --check --diff src/python/
      
      # Run linting
      - run:
          name: Run flake8 linting
          command: |
            source venv/bin/activate
            flake8 src/python/ --max-line-length=88 --extend-ignore=E203,W503
      
      # Run type checking
      - run:
          name: Run mypy type checking
          command: |
            source venv/bin/activate
            mypy src/python/ --ignore-missing-imports --no-strict-optional
      
      # Create test results directory
      - run:
          name: Create test directories
          command: |
            mkdir -p test-results/python
            mkdir -p artifacts/python
      
      # Run unit tests with coverage
      - run:
          name: Run Python unit tests
          command: |
            source venv/bin/activate
            pytest src/tests/python_tests/ \
              --junitxml=test-results/python/junit.xml \
              --html=artifacts/python/report.html \
              --self-contained-html \
              --cov=src/python \
              --cov-report=html:artifacts/python/coverage \
              --cov-report=xml:artifacts/python/coverage.xml \
              -v
      
      # Run integration tests
      - run:
          name: Run Python integration tests
          command: |
            source venv/bin/activate
            pytest src/tests/python_tests/test_ml_models_integration.py \
              --junitxml=test-results/python/integration-junit.xml \
              -v
      
      # Save test results and artifacts
      - save_test_results:
          test_results_path: "test-results"
          artifacts_path: "artifacts"

  # C++ compilation and testing job
  cpp-test:
    executor: cpp-executor
    resource_class: medium
    steps:
      - checkout_and_cache
      
      # Install C++ build tools
      - run:
          name: Install build dependencies
          command: |
            sudo apt-get update
            sudo apt-get install -y build-essential cmake libgtest-dev
            # Build and install Google Test
            cd /usr/src/gtest
            sudo cmake CMakeLists.txt
            sudo make
            sudo cp lib/*.a /usr/lib
      
      # Restore C++ build cache
      - restore_cache:
          keys:
            - cpp-build-v1-{{ checksum "src/tests/cpp_tests/CMakeLists.txt" }}-{{ checksum "/tmp/month-cache-key" }}
            - cpp-build-v1-
      
      # Create build directory
      - run:
          name: Create build directory
          command: |
            mkdir -p build
            mkdir -p test-results/cpp
            mkdir -p artifacts/cpp
      
      # Build C++ components
      - run:
          name: Build C++ components
          command: |
            cd src/tests/cpp_tests
            cmake -B ../../../build -S .
            cmake --build ../../../build --config Release
      
      # Save C++ build cache
      - save_cache:
          key: cpp-build-v1-{{ checksum "src/tests/cpp_tests/CMakeLists.txt" }}-{{ checksum "/tmp/month-cache-key" }}
          paths:
            - build
      
      # Run C++ tests
      - run:
          name: Run C++ unit tests
          command: |
            cd build
            # Run tests and capture output
            ./test_order_book --gtest_output=xml:../test-results/cpp/junit.xml || true
            # Copy test results
            cp ../test-results/cpp/junit.xml ../artifacts/cpp/ || true
      
      # Save test results and artifacts
      - save_test_results:
          test_results_path: "test-results"
          artifacts_path: "artifacts"

  # R testing job
  r-test:
    executor: r-executor
    resource_class: medium
    steps:
      - checkout_and_cache
      
      # Install system dependencies for R packages
      - run:
          name: Install system dependencies
          command: |
            apt-get update
            apt-get install -y libcurl4-openssl-dev libssl-dev libxml2-dev
      
      # Restore R packages cache
      - restore_cache:
          keys:
            - r-packages-v1-{{ checksum "/tmp/month-cache-key" }}
            - r-packages-v1-
      
      # Install R packages
      - run:
          name: Install R packages
          command: |
            R -e "
            if (!require('devtools')) install.packages('devtools', repos = 'http://cran.rstudio.com/')
            if (!require('testthat')) install.packages('testthat', repos = 'http://cran.rstudio.com/')
            if (!require('dplyr')) install.packages('dplyr', repos = 'http://cran.rstudio.com/')
            if (!require('ggplot2')) install.packages('ggplot2', repos = 'http://cran.rstudio.com/')
            if (!require('forecast')) install.packages('forecast', repos = 'http://cran.rstudio.com/')
            if (!require('quantmod')) install.packages('quantmod', repos = 'http://cran.rstudio.com/')
            if (!require('PerformanceAnalytics')) install.packages('PerformanceAnalytics', repos = 'http://cran.rstudio.com/')
            if (!require('portfolio')) install.packages('portfolio', repos = 'http://cran.rstudio.com/')
            "
      
      # Save R packages cache
      - save_cache:
          key: r-packages-v1-{{ checksum "/tmp/month-cache-key" }}
          paths:
            - /usr/local/lib/R/site-library
      
      # Create test directories
      - run:
          name: Create test directories
          command: |
            mkdir -p test-results/r
            mkdir -p artifacts/r
      
      # Run R tests
      - run:
          name: Run R unit tests
          command: |
            R -e "
            library(testthat)
            # Test statistical models
            test_results <- test_dir('src/tests/R_tests/', reporter = 'junit')
            # Save test results (basic implementation)
            cat('R tests completed\n')
            " > artifacts/r/test_output.txt
      
      # Check R code syntax
      - run:
          name: Check R code syntax
          command: |
            R -e "
            # Check syntax of R files
            files <- list.files('src/R/', pattern = '\\.R$', recursive = TRUE, full.names = TRUE)
            for (file in files) {
              tryCatch({
                parse(file)
                cat('✓ Syntax OK:', file, '\n')
              }, error = function(e) {
                cat('✗ Syntax Error in', file, ':', e$message, '\n')
                quit(status = 1)
              })
            }
            " > artifacts/r/syntax_check.txt
      
      # Save test results and artifacts
      - save_test_results:
          test_results_path: "test-results"
          artifacts_path: "artifacts"

  # kdb+ testing job
  kdb-test:
    executor: kdb-executor
    resource_class: small
    steps:
      - checkout_and_cache
      
      # Create test directories
      - run:
          name: Create test directories
          command: |
            mkdir -p test-results/kdb
            mkdir -p artifacts/kdb
      
      # Test kdb+ schema files
      - run:
          name: Test kdb+ schema validation
          command: |
            # Test trades schema
            q -c 25 100 -p 5001 src/kdb+/schema/trades.q < /dev/null > artifacts/kdb/trades_schema_test.log 2>&1 || true
            
            # Test quotes schema  
            q -c 25 100 -p 5002 src/kdb+/schema/quotes.q < /dev/null > artifacts/kdb/quotes_schema_test.log 2>&1 || true
            
            # Basic syntax check
            echo "Schema files tested" > test-results/kdb/basic_test.txt
      
      # Test analytics queries
      - run:
          name: Test kdb+ analytics queries
          command: |
            # Test analytics queries (basic syntax check)
            q -c 25 100 -p 5003 src/kdb+/queries/analytics.q < /dev/null > artifacts/kdb/analytics_test.log 2>&1 || true
            
            echo "Analytics queries tested" >> test-results/kdb/basic_test.txt
      
      # Test data feed handler
      - run:
          name: Test kdb+ data feed handler
          command: |
            # Test data feed handler (basic syntax check)
            q -c 25 100 -p 5004 src/kdb+/feeds/data_feed_handler.q < /dev/null > artifacts/kdb/feed_handler_test.log 2>&1 || true
            
            echo "Data feed handler tested" >> test-results/kdb/basic_test.txt
      
      # Save test results and artifacts
      - save_test_results:
          test_results_path: "test-results"
          artifacts_path: "artifacts"

  # MATLAB testing job (optional - requires license)
  matlab-test:
    executor: matlab-executor
    resource_class: medium
    steps:
      - checkout_and_cache
      
      # Create test directories
      - run:
          name: Create test directories
          command: |
            mkdir -p test-results/matlab
            mkdir -p artifacts/matlab
      
      # Test MATLAB functions
      - run:
          name: Test MATLAB quantitative methods
          command: |
            # Test basic MATLAB syntax and functions
            matlab -batch "
            try
              addpath('src/matlab/quantitative_methods/');
              addpath('src/matlab/simulation/');
              
              % Test basic functionality
              fprintf('Testing MATLAB components...\n');
              
              % Test if functions can be loaded
              which('quant_methods.m')
              which('market_sim.m')
              
              fprintf('MATLAB tests completed successfully\n');
              exit(0);
            catch ME
              fprintf('MATLAB test failed: %s\n', ME.message);
              exit(1);
            end
            " > artifacts/matlab/test_output.txt 2>&1 || echo "MATLAB test completed with warnings"
      
      # Save test results and artifacts
      - save_test_results:
          test_results_path: "test-results"
          artifacts_path: "artifacts"

  # Jupyter notebooks validation
  notebook-test:
    executor: python-executor
    resource_class: small
    steps:
      - checkout_and_cache
      
      # Restore Python dependencies cache
      - restore_cache:
          keys:
            - python-deps-v2-{{ checksum "requirements.txt" }}-{{ checksum "/tmp/month-cache-key" }}
            - python-deps-v2-
      
      # Install notebook testing tools
      - run:
          name: Install notebook testing dependencies
          command: |
            python -m venv venv
            source venv/bin/activate
            pip install jupyter nbconvert nbformat
      
      # Create test directories
      - run:
          name: Create test directories
          command: |
            mkdir -p test-results/notebooks
            mkdir -p artifacts/notebooks
      
      # Validate notebook structure
      - run:
          name: Validate Jupyter notebooks
          command: |
            source venv/bin/activate
            
            # Find all notebook files
            find notebooks/ -name "*.ipynb" -type f > artifacts/notebooks/notebook_list.txt
            
            # Validate each notebook
            while IFS= read -r notebook; do
              echo "Validating: $notebook"
              jupyter nbconvert --to notebook --execute --inplace "$notebook" --ExecutePreprocessor.timeout=60 || echo "Warning: $notebook validation failed"
            done < artifacts/notebooks/notebook_list.txt
            
            echo "Notebook validation completed" > test-results/notebooks/validation.txt
      
      # Save test results and artifacts
      - save_test_results:
          test_results_path: "test-results"
          artifacts_path: "artifacts"

  # Security and dependency scanning
  security-scan:
    executor: python-executor
    resource_class: small
    steps:
      - checkout_and_cache
      
      # Install security scanning tools
      - run:
          name: Install security tools
          command: |
            python -m venv venv
            source venv/bin/activate
            pip install safety bandit semgrep
      
      # Create test directories
      - run:
          name: Create test directories
          command: |
            mkdir -p test-results/security
            mkdir -p artifacts/security
      
      # Run safety check for Python dependencies
      - run:
          name: Check Python dependencies for vulnerabilities
          command: |
            source venv/bin/activate
            safety check --json > artifacts/security/safety_report.json || true
            safety check > artifacts/security/safety_report.txt || true
      
      # Run bandit security linter
      - run:
          name: Run Bandit security analysis
          command: |
            source venv/bin/activate
            bandit -r src/python/ -f json -o artifacts/security/bandit_report.json || true
            bandit -r src/python/ > artifacts/security/bandit_report.txt || true
      
      # Create security summary
      - run:
          name: Create security summary
          command: |
            echo "Security scan completed" > test-results/security/summary.txt
            echo "Check artifacts/security/ for detailed reports" >> test-results/security/summary.txt
      
      # Save test results and artifacts
      - save_test_results:
          test_results_path: "test-results"
          artifacts_path: "artifacts"

# Define workflows
workflows:
  version: 2
  
  # Main build and test workflow
  build_and_test:
    jobs:
      # Core language testing (run in parallel)
      - python-test:
          filters:
            branches:
              ignore: 
                - gh-pages
      
      - cpp-test:
          filters:
            branches:
              ignore: 
                - gh-pages
      
      - r-test:
          filters:
            branches:
              ignore: 
                - gh-pages
      
      # Specialized testing (run after core tests)
      - kdb-test:
          requires:
            - python-test
          filters:
            branches:
              ignore: 
                - gh-pages
      
      - matlab-test:
          requires:
            - python-test
          filters:
            branches:
              ignore: 
                - gh-pages
      
      - notebook-test:
          requires:
            - python-test
          filters:
            branches:
              ignore: 
                - gh-pages
      
      - security-scan:
          requires:
            - python-test
          filters:
            branches:
              ignore: 
                - gh-pages

  # Nightly comprehensive testing
  nightly:
    triggers:
      - schedule:
          cron: "0 2 * * *"  # Run at 2 AM UTC
          filters:
            branches:
              only:
                - main
                - master
    jobs:
      - python-test
      - cpp-test
      - r-test
      - kdb-test
      - matlab-test
      - notebook-test
      - security-scan

  # Release workflow (for tagged releases)
  release:
    jobs:
      - python-test:
          filters:
            tags:
              only: /^v.*/
            branches:
              ignore: /.*/
      
      - cpp-test:
          filters:
            tags:
              only: /^v.*/
            branches:
              ignore: /.*/
      
      - r-test:
          filters:
            tags:
              only: /^v.*/
            branches:
              ignore: /.*/
      
      - kdb-test:
          requires:
            - python-test
          filters:
            tags:
              only: /^v.*/
            branches:
              ignore: /.*/
      
      - matlab-test:
          requires:
            - python-test
          filters:
            tags:
              only: /^v.*/
            branches:
              ignore: /.*/
      
      - notebook-test:
          requires:
            - python-test
          filters:
            tags:
              only: /^v.*/
            branches:
              ignore: /.*/
      
      - security-scan:
          requires:
            - python-test
          filters:
            tags:
              only: /^v.*/
            branches:
              ignore: /.*/
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "195ae659",
   "metadata": {},
   "source": [
    "# Machine Learning Model Research for Statistical Arbitrage\n",
    "\n",
    "This notebook explores various machine learning approaches for developing predictive models in statistical arbitrage strategies. We'll experiment with different algorithms, feature engineering techniques, and model validation approaches.\n",
    "\n",
    "## Research Objectives\n",
    "- Explore various ML algorithms for return prediction\n",
    "- Develop robust feature engineering pipelines\n",
    "- Implement proper cross-validation for time series data\n",
    "- Compare model performance and stability\n",
    "- Test ensemble methods and model combinations\n",
    "\n",
    "## Models to Investigate\n",
    "1. **Linear Models**: Ridge, Lasso, Elastic Net\n",
    "2. **Tree-Based Models**: Random Forest, XGBoost, LightGBM\n",
    "3. **Neural Networks**: Feed-forward, LSTM, GRU\n",
    "4. **Ensemble Methods**: Voting, Stacking, Blending\n",
    "5. **Time Series Models**: ARIMA-GARCH, State Space Models\n",
    "6. **Clustering**: K-Means for regime identification\n",
    "\n",
    "## Key Research Questions\n",
    "- Can ML models predict short-term return patterns?\n",
    "- Which features are most predictive of future returns?\n",
    "- How do models perform across different market regimes?\n",
    "- What is the optimal lookback period for features?\n",
    "- How can we combine multiple models effectively?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155f6e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Advanced ML libraries\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGB_AVAILABLE = False\n",
    "    print(\"XGBoost not available\")\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    LGB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LGB_AVAILABLE = False\n",
    "    print(\"LightGBM not available\")\n",
    "\n",
    "# Deep learning (optional)\n",
    "try:\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    KERAS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    KERAS_AVAILABLE = False\n",
    "    print(\"Keras/TensorFlow not available\")\n",
    "\n",
    "# Financial data\n",
    "import yfinance as yf\n",
    "from scipy import stats\n",
    "import talib\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"XGBoost available: {XGB_AVAILABLE}\")\n",
    "print(f\"LightGBM available: {LGB_AVAILABLE}\")\n",
    "print(f\"Keras available: {KERAS_AVAILABLE}\")\n",
    "\n",
    "# Load data for experimentation\n",
    "def load_experimental_data():\n",
    "    \"\"\"Load and prepare data for ML experiments\"\"\"\n",
    "    \n",
    "    # Define stock universe\n",
    "    stocks = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', \n",
    "              'JPM', 'BAC', 'WFC', 'GS', 'MS',\n",
    "              'XOM', 'CVX', 'COP', 'EOG', 'SLB']\n",
    "    \n",
    "    try:\n",
    "        # Download 3 years of data\n",
    "        print(\"Downloading market data...\")\n",
    "        price_data = yf.download(stocks, period=\"3y\", interval=\"1d\")['Adj Close']\n",
    "        \n",
    "        # Calculate returns and other metrics\n",
    "        returns = price_data.pct_change()\n",
    "        log_returns = np.log(price_data / price_data.shift(1))\n",
    "        \n",
    "        # Volume data for additional features\n",
    "        volume_data = yf.download(stocks, period=\"3y\", interval=\"1d\")['Volume']\n",
    "        \n",
    "        print(f\"Data loaded: {len(stocks)} stocks, {len(price_data)} days\")\n",
    "        return price_data, returns, log_returns, volume_data, stocks\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        print(\"Creating synthetic data for experimentation...\")\n",
    "        \n",
    "        # Generate synthetic data\n",
    "        dates = pd.date_range(start='2021-01-01', end='2024-01-01', freq='D')\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        price_data = pd.DataFrame({\n",
    "            stock: 100 * np.exp(np.cumsum(np.random.normal(0.0005, 0.02, len(dates))))\n",
    "            for stock in stocks\n",
    "        }, index=dates)\n",
    "        \n",
    "        returns = price_data.pct_change()\n",
    "        log_returns = np.log(price_data / price_data.shift(1))\n",
    "        \n",
    "        # Synthetic volume\n",
    "        volume_data = pd.DataFrame({\n",
    "            stock: np.random.randint(1000000, 10000000, len(dates))\n",
    "            for stock in stocks\n",
    "        }, index=dates)\n",
    "        \n",
    "        return price_data, returns, log_returns, volume_data, stocks\n",
    "\n",
    "# Load the experimental dataset\n",
    "price_data, returns, log_returns, volume_data, stocks = load_experimental_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f061326f",
   "metadata": {},
   "source": [
    "## 1. Feature Engineering for ML Models\n",
    "\n",
    "Creating a comprehensive set of predictive features from price, volume, and market data for our ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238d90ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(price_data, returns, volume_data, stock_symbol, lookback_periods=[5, 10, 20]):\n",
    "    \"\"\"\n",
    "    Create comprehensive feature set for ML models\n",
    "    \"\"\"\n",
    "    features = pd.DataFrame(index=price_data.index)\n",
    "    \n",
    "    # Price-based features\n",
    "    prices = price_data[stock_symbol]\n",
    "    stock_returns = returns[stock_symbol]\n",
    "    volumes = volume_data[stock_symbol] if volume_data is not None else None\n",
    "    \n",
    "    # 1. Lagged returns\n",
    "    for lag in range(1, 6):  # 1-5 day lags\n",
    "        features[f'return_lag_{lag}'] = stock_returns.shift(lag)\n",
    "    \n",
    "    # 2. Moving averages and ratios\n",
    "    for period in lookback_periods:\n",
    "        features[f'ma_{period}'] = prices.rolling(period).mean()\n",
    "        features[f'price_to_ma_{period}'] = prices / features[f'ma_{period}']\n",
    "        features[f'ma_slope_{period}'] = (features[f'ma_{period}'] - features[f'ma_{period}'].shift(5)) / 5\n",
    "    \n",
    "    # 3. Volatility measures\n",
    "    for period in lookback_periods:\n",
    "        features[f'volatility_{period}'] = stock_returns.rolling(period).std()\n",
    "        features[f'volatility_ratio_{period}'] = (features[f'volatility_{period}'] / \n",
    "                                                 features[f'volatility_{period}'].shift(period))\n",
    "    \n",
    "    # 4. Price momentum and mean reversion\n",
    "    for period in lookback_periods:\n",
    "        features[f'momentum_{period}'] = (prices / prices.shift(period) - 1)\n",
    "        features[f'mean_reversion_{period}'] = (prices - prices.rolling(period).mean()) / prices.rolling(period).std()\n",
    "    \n",
    "    # 5. Technical indicators\n",
    "    if len(prices.dropna()) > 50:  # Ensure sufficient data\n",
    "        try:\n",
    "            # RSI\n",
    "            features['rsi_14'] = pd.Series(talib.RSI(prices.values, timeperiod=14), index=prices.index)\n",
    "            \n",
    "            # MACD\n",
    "            macd, macd_signal, macd_hist = talib.MACD(prices.values)\n",
    "            features['macd'] = pd.Series(macd, index=prices.index)\n",
    "            features['macd_signal'] = pd.Series(macd_signal, index=prices.index)\n",
    "            features['macd_histogram'] = pd.Series(macd_hist, index=prices.index)\n",
    "            \n",
    "            # Bollinger Bands\n",
    "            bb_upper, bb_middle, bb_lower = talib.BBANDS(prices.values)\n",
    "            features['bb_position'] = (prices - pd.Series(bb_lower, index=prices.index)) / (\n",
    "                pd.Series(bb_upper, index=prices.index) - pd.Series(bb_lower, index=prices.index))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Technical indicators failed: {e}\")\n",
    "            # Fill with simple alternatives\n",
    "            features['rsi_14'] = np.nan\n",
    "            features['macd'] = np.nan\n",
    "            features['bb_position'] = np.nan\n",
    "    \n",
    "    # 6. Volume features (if available)\n",
    "    if volumes is not None:\n",
    "        for period in lookback_periods:\n",
    "            features[f'volume_ma_{period}'] = volumes.rolling(period).mean()\n",
    "            features[f'volume_ratio_{period}'] = volumes / features[f'volume_ma_{period}']\n",
    "        \n",
    "        # Price-Volume features\n",
    "        features['price_volume_trend'] = (prices * volumes).rolling(20).sum()\n",
    "    \n",
    "    # 7. Cross-sectional features (relative to market)\n",
    "    market_return = returns.mean(axis=1)  # Simple market proxy\n",
    "    features['excess_return_1d'] = stock_returns - market_return\n",
    "    features['beta_20d'] = stock_returns.rolling(20).cov(market_return) / market_return.rolling(20).var()\n",
    "    \n",
    "    # 8. Time-based features\n",
    "    features['day_of_week'] = features.index.dayofweek\n",
    "    features['month'] = features.index.month\n",
    "    features['quarter'] = features.index.quarter\n",
    "    \n",
    "    # 9. Regime features\n",
    "    market_vol = market_return.rolling(20).std()\n",
    "    features['high_vol_regime'] = (market_vol > market_vol.rolling(60).quantile(0.7)).astype(int)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Create features for the first few stocks\n",
    "print(\"Creating features for ML models...\")\n",
    "feature_datasets = {}\n",
    "\n",
    "for i, stock in enumerate(stocks[:3]):  # Start with 3 stocks for testing\n",
    "    print(f\"Processing {stock}...\")\n",
    "    features = create_features(price_data, returns, volume_data, stock)\n",
    "    \n",
    "    # Create target variable (next day return)\n",
    "    features['target'] = returns[stock].shift(-1)  # Next day return\n",
    "    \n",
    "    # Remove rows with NaN values\n",
    "    features_clean = features.dropna()\n",
    "    \n",
    "    feature_datasets[stock] = features_clean\n",
    "    print(f\"  Features created: {features_clean.shape}\")\n",
    "\n",
    "# Display feature summary\n",
    "sample_stock = stocks[0]\n",
    "sample_features = feature_datasets[sample_stock]\n",
    "\n",
    "print(f\"\\n=== FEATURE SUMMARY FOR {sample_stock} ===\")\n",
    "print(f\"Total features: {sample_features.shape[1] - 1}\")  # -1 for target\n",
    "print(f\"Data points: {sample_features.shape[0]}\")\n",
    "print(f\"Date range: {sample_features.index.min()} to {sample_features.index.max()}\")\n",
    "\n",
    "print(\"\\nFeature categories:\")\n",
    "feature_names = [col for col in sample_features.columns if col != 'target']\n",
    "print(f\"Price/Return features: {len([f for f in feature_names if 'return' in f or 'momentum' in f])}\")\n",
    "print(f\"Technical indicators: {len([f for f in feature_names if any(x in f for x in ['rsi', 'macd', 'bb'])])}\")\n",
    "print(f\"Volume features: {len([f for f in feature_names if 'volume' in f])}\")\n",
    "print(f\"Cross-sectional: {len([f for f in feature_names if 'excess' in f or 'beta' in f])}\")\n",
    "print(f\"Time features: {len([f for f in feature_names if any(x in f for x in ['day', 'month', 'quarter'])])}\")\n",
    "\n",
    "# Show sample of features\n",
    "print(f\"\\nSample features for {sample_stock}:\")\n",
    "print(sample_features.head()[['target'] + feature_names[:10]].round(4))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
